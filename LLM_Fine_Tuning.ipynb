{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plz77/LLM-Fine-Tuning/blob/main/LLM_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 1: Fine-Tuning LLM\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "Modul Pelatihan: Fine-Tuning LLM (GPT-2) untuk Edukasi\n",
        "--------------------------------------------------------------------------------\n",
        "Halo semuanya! Hari ini kita akan belajar cara \"mengajari\" sebuah kecerdasan\n",
        "buatan (LLM) agar lebih pintar dalam konteks pendidikan di Indonesia.\n",
        "\n",
        "Apa itu Fine-Tuning?\n",
        "Ibarat kita punya asisten yang pintar bahasa Inggris secara umum (GPT-2),\n",
        "kita akan memberinya \"kursus kilat\" agar ia memahami istilah kurikulum\n",
        "dan metode belajar di Indonesia.\n",
        "\n",
        "Istilah Penting:\n",
        "1. Epoch: Berapa kali model membaca seluruh dataset (buku) dari awal sampai akhir.\n",
        "2. Tokenisasi: Proses mengubah kata menjadi angka agar komputer bisa mengerti.\n",
        "3. Inference: Tahap pengujian atau penggunaan model setelah ia selesai belajar.\n",
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "wOcR58M44sSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import (\n",
        "    GPT2Tokenizer,\n",
        "    GPT2LMHeadModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Step 1: Persiapan Lingkungan (Environment)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "def train_edu_model():\n",
        "    print(\"--- Memulai Modul Pembelajaran Fine-Tuning ---\")\n",
        "\n",
        "    # Step 2: Memilih Model Dasar (Base Model)\n",
        "    model_name = \"gpt2\"\n",
        "    print(f\"1. Memuat model dasar: {model_name}...\")\n",
        "\n",
        "    try:\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cpu\")\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal memuat model: {e}\")\n",
        "        return # Sekarang return berada di dalam fungsi yang benar\n",
        "\n",
        "    # Step 3: Menyiapkan Dataset Pendidikan (Dataset diperkaya)\n",
        "    print(\"2. Menyiapkan materi dataset pendidikan...\")\n",
        "    data_samples = [\n",
        "        {\"text\": \"Pendidikan di Indonesia menggunakan Kurikulum Merdeka untuk fleksibilitas belajar.\"},\n",
        "        {\"text\": \"Kecerdasan Buatan atau AI adalah subjek penting untuk masa depan siswa Gen Z.\"},\n",
        "        {\"text\": \"Algoritma adalah urutan langkah logis untuk menyelesaikan masalah komputasi.\"},\n",
        "        {\"text\": \"Machine Learning memungkinkan komputer belajar dari data tanpa pemrograman.\"},\n",
        "        {\"text\": \"Python adalah bahasa pemrograman populer untuk pengembangan kecerdasan buatan.\"},\n",
        "        {\"text\": \"Literasi digital sangat penting bagi guru dan siswa di era modern.\"},\n",
        "        {\"text\": \"Cloud Computing mempermudah akses penyimpanan data pendidikan secara online.\"},\n",
        "        {\"text\": \"Siswa belajar coding untuk meningkatkan kemampuan logika dan problem solving.\"},\n",
        "        {\"text\": \"Teknologi masa depan akan sangat bergantung pada inovasi di bidang AI.\"},\n",
        "        {\"text\": \"Guru berperan sebagai fasilitator dalam ekosistem pendidikan digital.\"},\n",
        "        {\"text\": \"Pendidikan masa depan mengutamakan kolaborasi antara manusia dan teknologi AI.\"},\n",
        "        {\"text\": \"Kurikulum Merdeka memberikan kebebasan bagi guru untuk berinovasi di kelas.\"},\n",
        "        {\"text\": \"Siswa harus menguasai keterampilan digital untuk bersaing di pasar kerja global.\"},\n",
        "        {\"text\": \"Teknologi informatika menjadi pilar utama dalam transformasi sekolah digital.\"},\n",
        "        {\"text\": \"Metode pembelajaran berbasis proyek membantu siswa berpikir lebih kritis.\"}\n",
        "    ]\n",
        "\n",
        "    raw_dataset = Dataset.from_list(data_samples)\n",
        "\n",
        "    # Step 4: Tokenisasi\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=64)\n",
        "\n",
        "    print(\"3. Proses tokenisasi data...\")\n",
        "    tokenized_datasets = raw_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "    # Step 5: Konfigurasi Pelatihan\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./gpt2-edu-result\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=10,\n",
        "        per_device_train_batch_size=1,\n",
        "        no_cuda=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Step 6: Proses Belajar (Training)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=tokenized_datasets,\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Proses Fine-Tuning Dimulai ---\")\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\"Training selesai!\")\n",
        "\n",
        "        # Menyimpan model hasil pelatihan\n",
        "        model.save_pretrained(\"./model-finetuning-kita\")\n",
        "        tokenizer.save_pretrained(\"./model-finetuning-kita\")\n",
        "        print(\"Model berhasil disimpan di folder: ./model-finetuning-kita\")\n",
        "\n",
        "        # Step 7: Ujian Akhir (Inference)\n",
        "        print(\"\\n--- Tahap Pengujian (Inference) ---\")\n",
        "        generator = pipeline(\n",
        "            'text-generation',\n",
        "            model=\"./model-finetuning-kita\",\n",
        "            tokenizer=\"./model-finetuning-kita\",\n",
        "            device=-1\n",
        "        )\n",
        "\n",
        "        prompt = \"Pendidikan masa depan\"\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "\n",
        "        output = generator(\n",
        "            prompt,\n",
        "            max_new_tokens=25,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_k=50\n",
        "        )\n",
        "\n",
        "        print(\"\\nHasil Generasi AI:\")\n",
        "        print(f\"{output[0]['generated_text']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTerjadi kesalahan selama proses: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_edu_model()"
      ],
      "metadata": {
        "id": "fc0Z4Uzo03oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDsis3QA3lvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}